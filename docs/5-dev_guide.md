# 开发指南与架构规范：实现原子性事务

## 引言：核心技术挑战与目标

本指南为CoreTerra项目的开发者确立了一套明确且强制性的实现规范。我们的核心技术任务是在三个独立的系统——文件系统（MyST Markdown文件）、Git版本控制和SQLite数据库——之间实现原子性的事务操作。这意味着任何一项任务的创建、更新或删除，必须在这三个系统中同时成功，或者完全不执行，绝不允许出现因部分成功而导致的数据不一致状态。

此架构模式具有至关重要的战略意义，因为它使数据的完整性和可审计性成为不可妥协的系统属性。通过强制要求每次变更都生成不可篡改的Git审计追踪，我们不仅确保了系统的绝对可靠性，更为未来集成人工智能（AI）功能，特别是需要可信数据谱系的大语言模型（LLM），奠定了坚实的基础。以下，我们将深入探讨支撑这一设计的核心架构理念。

## 1. 核心架构理念

CoreTerra的架构基于一种特意设计的创新混合持久化模型，其核心目标是最大化数据的可审计性、可移植性与查询性能。理解这一设计理念是掌握后续所有技术决策的关键。该模型将系统的持久化层拆分为两个核心组件，并为未来的AI集成做好了充分准备。

### 1.1 混合存储模型分析

**MyST Markdown 文件 (真理之源 - Source of Truth)**: 在我们的模型中，每一个任务项都以一个独立的MyST Markdown文件的形式存储在文件系统中。我们将由Git进行版本控制的文件系统指定为系统中唯一且最终的"真理之源"（Source of Truth, SSOT）。

- **人类可读与可移植性**: MyST Markdown格式确保了每个任务的内容不仅机器可读，也对人类开发者友好，易于直接查看和理解。
- **结构化元数据**: 每个文件都必须包含一个YAML frontmatter头部，该头部遵循MyST规范（Configuration and content frontmatter - MyST Markdown），用于定义任务的结构化元数据，如状态（status）、优先级（priority）、截止日期（due_date）等。
- **与生俱来的版本控制**: 将文件存储在Git仓库中，每一次对任务的修改都会生成一次Git提交（commit）。这为我们提供了与生俱来的、粒度化的版本控制能力，使得追踪任务的每一次变更历史变得简单而可靠。

**SQLite 数据库 (可搜索元数据索引 - Searchable Metadata Index)**: 与SSOT相辅相成，SQLite数据库在本架构中扮演的角色并非主数据存储，而是一个高性能的"可搜索元数据索引"（Searchable Metadata Index, SMI）。

- **角色定位**: 该数据库仅镜像（mirror）MyST Markdown文件frontmatter中的关键元数据字段，例如id, status, priority, tags等。任务的详细描述（body）等非结构化内容则不存储于数据库中。
- **性能优化**: 采用此索引策略的根本原因是为了解决性能瓶颈。在需要展示任务列表或根据元数据进行过滤查询时，直接读取并解析成百上千个Markdown文件会带来巨大的I/O和计算开销。通过查询SQLite索引，系统可以毫秒级地获取渲染列表视图所需的所有元数据，从而极大地提升了前端应用的性能和用户体验。

### 1.2 论证AI就绪设计 (AI-Readiness)

尽管MVP（最小可行产品）阶段不包含AI功能，但整个架构从设计之初就充分考虑了未来的AI集成需求。

- **为LLM提供结构化上下文**: MyST frontmatter提供的结构化元数据（如标签、截止日期）对于未来集成大语言模型至关重要。这些结构化字段为模型提供了清晰的上下文，使其能够高效地区分任务属性，从而实现更精准的自动化分析。
- **Git提供不可变的数据谱系**: Git的加密完整性为每一次任务状态的变更都建立了一个完整的、不可变的审计追踪。这种可验证的数据谱系（verifiable data lineage）是构建可信赖机器学习模型的基石。它允许工程师在任何时间点对训练数据集进行完全复现，这对于满足合规性要求和调试模型行为至关重要。

这些架构原则通过一个清晰的代码库结构得以实现，确保了各个组件的职责分离与高效协作。

## 2. Monorepo 代码库结构

为了在后端服务、前端界面和命令行工具之间保持清晰的关注点分离，并提升开发和维护效率，项目采用Monorepo（单一代码库）结构。一个逻辑清晰、约定一致的目录结构是确保项目长期可维护性的关键。

以下是CoreTerra项目的三大核心目录及其职责定义：

- **/backend**
  - **职责**: 存放所有与API服务及核心业务逻辑相关的代码。
  - **技术栈**: 基于Python和FastAPI构建。
  - **说明**: 这是系统的核心，负责处理所有的数据持久化逻辑，包括读写MyST文件、执行本地Git操作以及同步更新SQLite索引。所有的数据验证、业务规则和原子性事务的实现都集中于此。
- **/frontend**
  - **职责**: 存放所有用户界面（UI）相关的代码。
  - **技术栈**: 基于React构建。
  - **说明**: 该目录包含所有与用户交互和数据渲染相关的组件。它通过调用/backend提供的API来获取和修改任务数据，并将Markdown内容渲染为用户友好的视图。
- **/cli**
  - **职责**: 存放命令行界面（CLI）工具的代码。
  - **说明**: CLI是API的一个轻量级客户端层，为开发者和自动化脚本提供对核心功能的访问。在任何情况下，业务逻辑都不得在CLI中实现。这样做会造成系统行为的分裂，违背我们逻辑单一来源的原则，并导致不可避免的数据一致性错误。

理解了代码的组织结构后，下一章节将深入探讨这些代码如何实现系统最核心的功能——原子性写入。

## 3. 核心实现模式：原子性写入包装器

为确保文件系统、Git历史和数据库索引这三者之间的数据永远保持同步，所有创建、更新和删除（CUD）操作都必须通过一个"原子性写入包装器"（Atomic Write Wrapper）来执行。这个包装器是一个集中的业务逻辑层，其核心职责是保证一系列操作作为一个不可分割的单元，要么全部成功，要么全部回滚。

### 3.1 FastAPI中的同步与异步选择

在FastAPI中，一项关键的技术决策是：所有处理文件I/O和Git操作的API端点必须使用同步的`def`函数定义，而非异步的`async def`。

- **决策原因**: 文件写入和本地Git命令（如`git commit`）本质上是阻塞操作。如果在Python的异步事件循环（Event Loop）中直接执行，将阻塞整个服务进程。
- **实现机制**: 将这些端点定义为同步的`def`函数，FastAPI会自动在一个专用的线程池（dedicated threadpool）中执行它们。这样，耗时的阻塞操作将在后台线程中运行，而主事件循环则保持空闲，可以继续处理其他并发请求，从而维持API的高响应性。

### 3.2 原子写入序列

所有CUD操作必须严格遵循以下顺序执行。这个序列的设计确保了作为"真理之源"的文件和Git历史总是优先于作为"索引"的数据库被更新。

1. **文件系统写入**: 在文件系统中创建或更新对应的`.md` MyST Markdown文件。
2. **本地Git提交**: 将文件的变更暂存（stage）并提交（commit）到本地Git仓库。此步骤的成功是整个事务得以继续的必要条件。
3. **SQLite索引更新**: 在文件写入和Git提交均成功后，最后一步是更新SQLite数据库中的元数据索引。

### 3.3 错误处理与回滚策略

整个原子写入序列必须被包裹在一个`try...except`代码块中，以捕获任何可能发生的异常，并执行相应的回滚逻辑。

下表详细定义了在不同阶段操作失败时的回滚策略：

| 失败阶段 | 触发条件 | 回滚操作 |
|---------|---------|---------|
| 文件写入失败 | 操作系统返回I/O错误。 | 事务立即中止，不执行任何Git或数据库操作。向客户端返回500 Internal Server Error。 |
| Git提交失败 | Git命令执行失败。 | 1. 必须撤销文件系统的变更（例如，删除已创建的文件或将文件内容恢复到修改前的状态）。<br>2. 不执行任何数据库操作。<br>3. 向客户端返回500 Internal Server Error，并记录详细的Git错误日志。 |
| 数据库更新失败 | SQLite返回错误。 | 1. 这是一个严重的数据不一致状态，因为"真理之源"已更新，但"索引"更新失败。<br>2. 此时文件和Git提交已完成，无法自动回滚。<br>3. 必须触发一个高优先级的监控系统警报（例如，Sentry、Datadog）并创建工单以供手动工程干预。系统必须假定处于部分不一致状态，直到索引被协调。<br>4. 向客户端返回500 Internal Server Error，并明确指出索引可能已不同步。 |

原子性写入包装器是保证数据完整性的核心机制。其中，Git提交信息的标准化同样至关重要，这直接关系到系统的可审计性和未来的数据分析能力。

## 4. Git 操作与提交规范

在CoreTerra架构中，Git提交记录不仅是开发日志，更是机器可读的、结构化的元数据来源。标准化的Git提交历史是系统可审计性的核心，并直接服务于未来的AI分析能力。

### 4.1 代码层面的Git调用

在FastAPI后端，我们将使用成熟的Python库（如GitPython）来编程式地执行本地的`git add`和`git commit`命令。此方法是强制性的，以避免直接调用`os.system`或`subprocess`，后者安全性较低且难以管理。

### 4.2 标准化的Commit Message模板

为了实现自动化的历史追溯和分析，所有由系统自动生成的Git提交都必须遵循严格的模板。模板的核心要素是操作类型和任务ID。

| 操作类型 | Commit Message 格式 | 示例 | AI分析价值 |
|---------|-------------------|------|-----------|
| 创建任务 | `ADD: {Task ID} - {Task Title}` | `ADD: COT-123 - Design the new API schema` | 建立一个精确的时间戳，用于计算交付周期（lead time）。 |
| 开始任务 | `START: {Task ID}` | `START: COT-123` | 建立一个精确的时间戳，用于计算"开始前时间"（time-to-start）。 |
| 完成任务 | `COMPLETE: {Task ID}` | `COMPLETE: COT-123` | 与START时间戳的差值提供了一个高度准确的"处理中时间"（time-in-process）度量，这对于计算速率和识别流程瓶颈至关重要。 |
| 修改任务 | `UPDATE: {Task ID} - {Change Description}` | `UPDATE: COT-123 - Increase priority to 5` | 提供任务元数据变更的细粒度、可审计历史，用于分析任务演变。 |
| 归档任务 | `ARCHIVE: {Task ID}` | `ARCHIVE: COT-123` | 标记任务活跃生命周期的结束点。 |

### 4.3 利用Git历史进行数据分析

通过标准化的提交，我们可以轻易地追溯单个任务的完整生命周期。例如，执行`git log -- COT-123.md`命令，即可精确返回与COT-123号任务相关的所有历史变更记录。

这种按时间序列组织的数据极具价值。未来的分析系统或AI模型可以解析这些日志，自动计算出任务处理周期、识别瓶颈，并为未来的任务速度和资源分配预测提供高质量的训练数据。

## 5. 前端与并发控制

在一个支持多客户端（Web UI 和 CLI）同时操作的系统中，必须设计一套稳健的并发控制机制。这不仅是为了保护数据的完整性，更是为了维护Git审计历史的纯洁性，防止因竞态条件（Race Condition）导致的数据覆盖或历史记录混乱。

### 5.1 React组件架构简述

React前端将采用成熟的组件驱动架构，以实现逻辑与渲染的清晰分离。

- **组件层次**: 架构将分为两类核心组件：
  - **容器组件 (Container Components)**: 如`TaskDataContainer`，负责处理应用的状态管理、数据获取逻辑以及与后端API的交互。
  - **展示组件 (Presentational Components)**: 如`TaskListView`，是纯粹的UI组件，仅负责根据通过props接收到的数据进行渲染。
- **单向数据流**: 状态和回调函数将从`TaskDataContainer`通过props向下传递给展示组件，强制执行严格的单向数据流。这种模式解耦了逻辑与渲染，使应用状态更易于追踪和调试。

### 5.2 详述乐观锁并发控制机制

乐观锁（Optimistic Locking）是解决并发修改问题的核心策略。它能有效防止一个用户的修改无意中覆盖掉另一个用户在此期间提交的修改。

**问题场景**: 用户A在Web UI中编辑任务COT-123。与此同时，用户B通过CLI命令将该任务的状态更新为"已完成"。如果用户A此时提交他的编辑，在没有并发控制的情况下，他的操作将覆盖掉用户B的状态更新。

**解决方案工作流**: 为了防止这种情况，所有修改数据的API请求（PUT/PATCH）必须实现以下乐观锁流程：

1. **客户端发送时间戳**: React客户端在发起更新请求时，必须在其请求体中包含该任务最后一次已知的`updated_at`时间戳。
2. **后端前置校验**: FastAPI后端在执行任何文件写入或Git提交操作之前，首先从SQLite索引中查询当前任务的`updated_at`时间戳。
3. **时间戳比较**: 后端严格比较客户端提交的时间戳与数据库中存储的时间戳。
4. **冲突检测与拒绝**: 如果数据库中的时间戳比客户端提供的更新，后端必须拒绝当前的更新请求，并向客户端返回`409 Conflict` HTTP状态码。
5. **客户端处理冲突**: 当React客户端接收到`409 Conflict`响应时，它必须强制重新获取任务数据，丢弃任何本地未保存的更改，并通知用户其视图已更新，因为该任务已被另一进程修改。

这种乐观锁策略是相对于悲观锁（例如文件级锁）的特意设计选择。它在预期的"小型内部团队"的低到中度竞争环境中，优先考虑了系统可用性和用户体验，同时仍然为Git审计追踪的完整性提供了强大的、不可妥协的保护。

结论

本指南详细阐述了CoreTerra项目的核心架构。其优势在于创新的混合持久化模型：以Git审计的MyST Markdown文件为不可变的“真理之源”，并以SQLite数据库作为高性能的“可搜索索引”。

为确保该架构的成功和长期可行性，所有开发者都必须强制遵守以下三项指令：

* 强制保证事务完整性: 必须严格遵循“原子性写入包装器”中定义的操作序列（文件写入 -> Git提交 -> 数据库更新），并为所有修改操作实现乐观锁并发控制机制。
* 维护索引健康: 系统必须提供一个维护命令（例如 cot index-rebuild）。该命令能够基于文件系统中的所有MyST文件，完全重建SQLite索引，以确保索引与真理之源的同步。
* 确保CLI/API对等: 必须坚持所有业务逻辑和数据验证规则只能存在于FastAPI后端。CLI工具应始终作为一个“薄客户端”，仅负责将用户命令转换为对等的API调用，以保证行为一致性。

遵循这些规范，我们不仅能满足当前MVP的需求，更为系统未来的智能化演进——无论是集成高级分析工具还是大语言模型——构建了一个坚实、可信且可扩展的数据基础。
